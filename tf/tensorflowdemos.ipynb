{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data @ Rice Workshop: Machine Learning / TensorFlow Interactive Notebook\n",
    "\n",
    "#### Corrin Fosmire\n",
    "#### November 14, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "This Jupyter notebook is going to be used to show examples of machine learning, beginning with simpler methods and extending to more complex ones.\n",
    " \n",
    "## Objectives\n",
    "\n",
    "Concretely, this workshop will teach you background on and basics of the following:\n",
    "\n",
    "* Machine Learning problems\n",
    "* Linear Regression and Logistic Regression\n",
    "* Neural Network Models\n",
    "* Reinforcement Learning\n",
    " \n",
    "This workshop is based on a series of labs created by Devika Subramanian for her COMP340 course at Rice University during the Fall 2018 term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyFxey-B1TMG"
   },
   "source": [
    "                                                                                                                       \n",
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data and visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10,8\n",
    "\n",
    "bdata = load_boston()\n",
    "df = pd.DataFrame(data = bdata.data, columns = bdata.feature_names)\n",
    "\n",
    "#  X is the percentage of the population in a census tract that is of\n",
    "#  lower economic status. X is a vector of length 506.\n",
    "#  y is to the median home value in $10000's. y is a vector of length 506\n",
    "\n",
    "X = df.LSTAT\n",
    "XX = np.vstack([np.ones((X.shape[0],)),X]).T\n",
    "y = bdata.target\n",
    "\n",
    "plt.scatter(X,y)\n",
    "plt.xlabel('Percentage of population with lower economic status')\n",
    "plt.ylabel('Median home value in $10000s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkPFiWB31TMd"
   },
   "source": [
    "###  Running sklearn's linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "653G0wC81TMf",
    "outputId": "0063f5fd-3d98-44d0-e149-3f6b04db9b31"
   },
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(XX,y)\n",
    "\n",
    "print(\"The coefficients computed by sklearn: \", lr.intercept_, \" and \", lr.coef_[1])\n",
    "modelx = np.linspace(0, 40, 80) # evenly spaced points every half-inch\n",
    "plt.plot(X, y, 'bo', modelx, lr.intercept_ + modelx * lr.coef_[1], 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a simple classification model and checking its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg = linear_model.LogisticRegression(solver='lbfgs')\n",
    "caty = 1 * (y > 20)\n",
    "Xp = np.array(X).reshape(-1, 1) # because we need input to be a matrix, not a vector\n",
    "logreg.fit(Xp,caty.astype(int))\n",
    "\n",
    "print(\"Accuracy:\",sum(logreg.predict(Xp) == caty.astype(int))/df.shape[0])\n",
    "confusion_matrix(logreg.predict(Xp), caty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow and Keras Modeling: Fully Connected Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (7,7) # Make the figures a bit bigger\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_x, img_y = 28,28\n",
    "X_train = X_train.reshape(60000, img_x*img_y)\n",
    "X_test = X_test.reshape(10000, img_x*img_y)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n",
    "                              # of the layer above. Here, with a \"rectified linear unit\",\n",
    "                              # we clamp all values below 0 to 0.\n",
    "                           \n",
    "model.add(Dropout(0.2))   # Dropout helps protect the model from memorizing or \"overfitting\" the training data\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax')) # This special \"softmax\" activation among other things,\n",
    "                                 # ensures the output is a valid probaility distribution, that is\n",
    "                                 # that its values are all non-negative and sum to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=128, epochs=10,\n",
    "          verbose=1,validation_data=(X_test, Y_test),\n",
    "          callbacks=[history])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "                        verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "plt.plot(range(1, 11), history.acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow and Keras Modeling: Convolutional Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "input_shape = (img_x, img_y, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_x, img_y, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_x, img_y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model_cnn.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(1000, activation='relu'))\n",
    "model_cnn.add(Dense(nb_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_cnn = AccuracyHistory()\n",
    "\n",
    "model_cnn.fit(X_train, Y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[history_cnn])\n",
    "\n",
    "score = model_cnn.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "plt.plot(range(1, 11), history_cnn.acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "lab1_partA.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
