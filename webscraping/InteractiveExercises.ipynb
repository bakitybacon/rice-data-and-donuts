{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data @ Rice Workshop: Web Scraping Interactive Exercises\n",
    "\n",
    "#### Corrin Fosmire\n",
    "#### October 14, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing a New York Times Article\n",
    "\n",
    "This workshop is going to teach web scraping, which is a general term for ways to acquire data from internet sources without using an officially provided API. We will do this using an article from the New York Times, which we will attempt to get the article text out of.\n",
    " \n",
    "## Objectives\n",
    "\n",
    "Concretely, this workshop will teach you how to work with:\n",
    "\n",
    "* Simple HTTP Requests \n",
    "* HTML Parsing with Beautiful Soup\n",
    " \n",
    "(this workshop is based on a series of labs created by Devika Subramanian for her COMP340 course at Rice University during the Fall 2018 term) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Setup\n",
    "\n",
    "Here, I'm importing a few libraries that we'll use throughout this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #for sending http requests to servers\n",
    "from bs4 import BeautifulSoup as bs #for parsing of the html we get back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Basic HTTP Requests\n",
    "\n",
    "Write a couple lines of code that uses the `requests` package in Python to download and return the raw HTML content of the URL passed in as an argument. As an example, try the following NYT article: [https://www.nytimes.com/2018/04/11/technology/personaltech/i-downloaded-the-information-that-facebook-has-on-me-yikes.html](https://www.nytimes.com/2018/04/11/technology/personaltech/i-downloaded-the-information-that-facebook-has-on-me-yikes.html)\n",
    "\n",
    "Make sure you save your result to a variable for the next problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE! (2-3 lines expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Extracting articles using BeautifulSoup\n",
    "\n",
    "Using `BeautifulSoup`, parse the HTML of the retrieved URL to extract the article. \n",
    "\n",
    "- to convert the HTML string `article` into a soup object: use `BeautifulSoup(article,\"lxml\")`\n",
    "- to find all paragraph tags in a soup object: use `soup.find_all(\"p\")`\n",
    "- to extract text from a paragraph object: use `p.getText()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE! (4-5 lines expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
